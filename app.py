#!/usr/bin/env python3
"""
AgentAru - Streamlit Web UI
Beautiful interface for your local AI agent
"""

import streamlit as st
import asyncio
import sys
from datetime import datetime
from dotenv import load_dotenv

sys.path.insert(0, '/Users/aravindgillella/projects/agentAru')

from src.core.model_manager import ModelManager
from src.mcp_integration.manager import initialize_mcp
from src.memory.memory_manager import AgentMemoryManager
from src.config.settings import settings
from langchain_core.messages import HumanMessage, AIMessage

load_dotenv()

# Page config
st.set_page_config(
    page_title="AgentAru - Local AI Agent",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        margin-bottom: 0.5rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        margin-bottom: 2rem;
    }
    .stat-box {
        padding: 1rem;
        border-radius: 0.5rem;
        background-color: #f0f2f6;
        margin: 0.5rem 0;
    }
    .tool-badge {
        display: inline-block;
        padding: 0.25rem 0.5rem;
        margin: 0.25rem;
        background-color: #e1f5fe;
        border-radius: 0.25rem;
        font-size: 0.9rem;
    }
</style>
""", unsafe_allow_html=True)


# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "agent_initialized" not in st.session_state:
    st.session_state.agent_initialized = False

if "mcp_manager" not in st.session_state:
    st.session_state.mcp_manager = None

if "llm" not in st.session_state:
    st.session_state.llm = None

if "memory_manager" not in st.session_state:
    st.session_state.memory_manager = None


async def initialize_agent():
    """Initialize all agent components"""
    if st.session_state.agent_initialized:
        return True

    with st.spinner("Initializing agent..."):
        try:
            # MCP
            mcp_manager = await initialize_mcp(auto_connect=False)
            await mcp_manager.connect_server_by_name("filesystem")
            st.session_state.mcp_manager = mcp_manager

            # Model
            model_manager = ModelManager()
            st.session_state.llm = model_manager.get_model()

            # Memory
            st.session_state.memory_manager = AgentMemoryManager(
                user_id="streamlit_user"
            )

            st.session_state.agent_initialized = True
            return True

        except Exception as e:
            st.error(f"Failed to initialize agent: {e}")
            return False


# Header
st.markdown('<div class="main-header">ğŸ¤– AgentAru</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Your Local AI Agent with MCP Tools</div>', unsafe_allow_html=True)

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Configuration")

    # Model info
    st.subheader("ğŸ§  Model")
    st.info(f"**{settings.default_model}**\n\nRunning locally via Ollama")

    # Initialize button
    if not st.session_state.agent_initialized:
        if st.button("ğŸš€ Initialize Agent", type="primary"):
            asyncio.run(initialize_agent())
            if st.session_state.agent_initialized:
                st.success("Agent initialized!")
                st.rerun()
    else:
        st.success("âœ… Agent Ready")

        # MCP Tools
        st.subheader("ğŸ”§ MCP Tools")
        if st.session_state.mcp_manager:
            tools = st.session_state.mcp_manager.tool_manager.get_tools()
            st.write(f"**{len(tools)} tools available:**")
            for tool in tools:
                st.markdown(f'<div class="tool-badge">{tool.name}</div>', unsafe_allow_html=True)

        # Memory stats
        st.subheader("ğŸ§  Memory")
        st.info("Using local Ollama embeddings\n- Nomic-embed-text\n- Qdrant vector store")

        # Actions
        st.subheader("Actions")
        if st.button("ğŸ—‘ï¸ Clear Chat"):
            st.session_state.messages = []
            st.rerun()

        if st.button("ğŸ’¾ View Memories"):
            st.session_state.show_memories = True

# Main chat area
if not st.session_state.agent_initialized:
    st.warning("ğŸ‘ˆ Click 'Initialize Agent' in the sidebar to get started")
    st.info("""
    **AgentAru Features:**
    - ğŸ  100% Local LLM (Qwen2.5 7B)
    - ğŸ§  Local Memory (Ollama embeddings)
    - ğŸ”§ MCP Filesystem Tools
    - ğŸš« No cloud API keys needed
    """)
else:
    # Display chat messages
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Chat input
    if prompt := st.chat_input("Ask me anything..."):
        # Add user message
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # Generate response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    response = st.session_state.llm.invoke(prompt)
                    response_text = response.content

                    st.markdown(response_text)

                    # Add to messages
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response_text
                    })

                    # Store in memory (async, non-blocking)
                    try:
                        st.session_state.memory_manager.add_interaction([
                            HumanMessage(content=prompt),
                            AIMessage(content=response_text)
                        ])
                    except:
                        pass

                except Exception as e:
                    st.error(f"Error: {e}")

# Show memories sidebar (if requested)
if st.session_state.get("show_memories", False):
    with st.sidebar:
        st.subheader("ğŸ’­ Recent Memories")
        if st.session_state.memory_manager:
            try:
                memories = st.session_state.memory_manager.search_memories(
                    "recent conversation",
                    limit=5
                )
                if memories:
                    for i, mem in enumerate(memories, 1):
                        st.text(f"{i}. {mem.get('memory', 'N/A')[:60]}...")
                else:
                    st.info("No memories yet")
            except:
                st.info("Memory search not available")

        if st.button("Close"):
            st.session_state.show_memories = False
            st.rerun()
